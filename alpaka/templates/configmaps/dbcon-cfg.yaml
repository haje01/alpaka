{{- if .Values.dbcon.enabled -}}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "common.names.fullname" . }}-dbcon-cfg
  labels: {{- include "common.labels.standard" . | nindent 4 }}
data:
  connect-distributed.properties: |
    # A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.
    bootstrap.servers = {{ .Release.Name }}-kafka-headless:{{ .Values.kafka.service.ports.client }}

    # unique name for the cluster, used in forming the Connect cluster group. Note that this must not conflict with consumer group IDs
    group.id=connect-cluster

    # The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will
    # need to configure these based on the format they want their data in when loaded from or stored into Kafka
    key.converter=org.apache.kafka.connect.json.JsonConverter
    value.converter=org.apache.kafka.connect.json.JsonConverter
    # Converter-specific settings can be passed in by prefixing the Converter's setting with the converter we want to apply
    # it to
    key.converter.schemas.enable=true
    value.converter.schemas.enable=true

    # Topic to use for storing offsets. This topic should have many partitions and be replicated and compacted.
    # Kafka Connect will attempt to create the topic automatically when needed, but you can always manually create
    # the topic before starting Kafka Connect if a specific topic configuration is needed.
    # Most users will want to use the built-in default replication factor of 3 or in some cases even specify a larger value.
    # Since this means there must be at least as many brokers as the maximum replication factor used, we'd like to be able
    # to run this example on a single-broker cluster and so here we instead set the replication factor to 1.
    offset.storage.topic=connect-offsets
    offset.storage.replication.factor=1
    #offset.storage.partitions=25

    # Topic to use for storing connector and task configurations; note that this should be a single partition, highly replicated,
    # and compacted topic. Kafka Connect will attempt to create the topic automatically when needed, but you can always manually create
    # the topic before starting Kafka Connect if a specific topic configuration is needed.
    # Most users will want to use the built-in default replication factor of 3 or in some cases even specify a larger value.
    # Since this means there must be at least as many brokers as the maximum replication factor used, we'd like to be able
    # to run this example on a single-broker cluster and so here we instead set the replication factor to 1.
    config.storage.topic=connect-configs
    config.storage.replication.factor=1

    # Topic to use for storing statuses. This topic can have multiple partitions and should be replicated and compacted.
    # Kafka Connect will attempt to create the topic automatically when needed, but you can always manually create# the topic before starting Kafka Connect if a specific topic configuration is needed.
    # Most users will want to use the built-in default replication factor of 3 or in some cases even specify a larger value.
    # Since this means there must be at least as many brokers as the maximum replication factor used, we'd like to be able
    # to run this example on a single-broker cluster and so here we instead set the replication factor to 1.
    status.storage.topic=connect-status
    status.storage.replication.factor=1
    #status.storage.partitions=5

    # Flush much faster than normal, which is useful for testing/debugging
    offset.flush.interval.ms=10000

    # List of comma-separated URIs the REST API will listen on. The supported protocols are HTTP and HTTPS.
    # Specify hostname as 0.0.0.0 to bind to all interfaces.
    # Leave hostname empty to bind to default interface.
    # Examples of legal listener lists: HTTP://myhost:8083,HTTPS://myhost:8084"
    #listeners=HTTP://:8083

    # The Hostname & Port that will be given out to other workers to connect to i.e. URLs that are routable from other servers.
    # If not set, it uses the value for "listeners" if configured.
    #rest.advertised.host.name=
    #rest.advertised.port=
    #rest.advertised.listener=

    # Set to a list of filesystem paths separated by commas (,) to enable class loading isolation for plugins
    # (connectors, converters, transformations). The list should consist of top level directories that include
    # any combination of:
    # a) directories immediately containing jars with plugins and their dependencies
    # b) uber-jars with plugins and their dependencies
    # c) directories immediately containing the package directory structure of classes of plugins and their dependencies
    # Examples:
    # plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins,/opt/connectors,
    plugin.path=/usr/share/java

  connect-log4j.properties: |
    log4j.rootLogger=INFO, stdout, connectAppender

    # Send the logs to the console.
    #
    log4j.appender.stdout=org.apache.log4j.ConsoleAppender
    log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
    log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n

    log4j.appender.connectAppender=org.apache.log4j.DailyRollingFileAppender
    log4j.appender.connectAppender.DatePattern='.'yyyy-MM-dd-HH
    log4j.appender.connectAppender.layout=org.apache.log4j.PatternLayout
    log4j.appender.connectAppender.layout.ConversionPattern=[%d] %p %m (%c)%n

    log4j.logger.org.apache.zookeeper=ERROR
    log4j.logger.org.reflections=ERROR
{{- end -}}